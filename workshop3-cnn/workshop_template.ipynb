{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop_template",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1mh-N5vOX7G5weVNYzCpui1Unosu5ahgj",
          "timestamp": 1526080756917
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ko0tAffRrvBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network and MNIST\n",
        "\n",
        "In this tutorial, we'll be walking through the Tensorflow code behind creating a convolutional neural network. If you'd like more of a conceptual view of how these networks work, check out my this blog post by Adit. A CNN tutorial from the Tensorflow docs can also be found here.\n",
        "\n",
        "A large part of the coding today will be keeping track of the dimensionality of the inputs, the outputs, the filters, and how they change as we set up the convolutional layers.\n"
      ]
    },
    {
      "metadata": {
        "id": "l_WmnHUnghM0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our Architecture:\n",
        "INPUT -> CONV1 -> RELU1 -> POOL1 -> CONV2 -> RELU2 -> POOL2 -> FC1 -> FC2 (OUTPUT, SOFTMAX)"
      ]
    },
    {
      "metadata": {
        "id": "RlM8Cb1VgFVi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Some imports, as usual:\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "%matplotlib inline\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7CfLyWI6geyb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the MNIST dataset\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Ed8RHkPxqNj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# defining some training hyperparameters\n",
        "learning_rate = 0.1\n",
        "num_epochs = 5000\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zP279pCtgtND",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# defining placeholders\n",
        "x = tf.placeholder(\"float\", shape = [None, 28, 28, 1]) # note the change in dimensionality\n",
        "y_ = tf.placeholder(\"float\", shape = [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3RKJFz9g-qR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hold up\n",
        "\n",
        "Why are we using [None, 28, 28, 1] as the input dimension?\n",
        "\n",
        "Note that this ordering remains consistent throughout the coding example for defining our dimensionalities."
      ]
    },
    {
      "metadata": {
        "id": "op-rFWhTnWg1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define some helper functions\n"
      ]
    },
    {
      "metadata": {
        "id": "ZY4iLf69mzJc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# padding = 1, strides = 1\n",
        "def conv2d(x, w):\n",
        "  return tf.nn.conv2d(input=x, filter=w, strides=[ , , , ], padding=\"SAME\")\n",
        "\n",
        "# padding = none, strides = 2, filter size = 2\n",
        "# note that the pool layer isn't parameterized by weights\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[ , , , ], strides=[ , , , ], padding=\"VALID\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxzsP-ZvrkfT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the first Conv-Relu-Pool layers\n",
        "\n",
        "What size filters should we have for the Convolutional Layer? Recall that we don't downsample in Conv Layer (for now) and instead leave that to "
      ]
    },
    {
      "metadata": {
        "id": "wV-9Y0hfhqaQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filters1 = 32\n",
        "\n",
        "w_conv1 = tf.Variable(tf.truncated_normal([ , , , ], stddev=0.1))\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape = [...]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gilkyUXlDea",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "h_conv1 = ...\n",
        "h_relu1 = tf.nn.relu(h_conv1)\n",
        "h_pool1 = ...\n",
        "\n",
        "# sanity checks for the output volume\n",
        "print(h_conv1)\n",
        "print(h_relu1)\n",
        "print(h_pool1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lbB-sgcdrqUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the second Conv-Relu-Pool layers"
      ]
    },
    {
      "metadata": {
        "id": "RShLEzYOrS9k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filters2 = 64\n",
        "\n",
        "w_conv2 = tf.Variable(tf.truncated_normal([ , , , ], stddev=0.1))\n",
        "b_conv2 = tf.Variable(tf.constant(0.1, shape=[...]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JS7Xm4lRs7-s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "h_conv2 = ...\n",
        "h_relu2 = tf.nn.relu(h_conv2)\n",
        "h_pool2 = ...\n",
        "\n",
        "# sanity checks for the output volume\n",
        "print(h_conv2)\n",
        "print(h_relu2)\n",
        "print(h_pool2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rcFu4L5-tO3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the first FC layer\n",
        "\n",
        "Recall the operation for the FC layer is:\n",
        "\\begin{equation*}\n",
        "h(x) = a(Wx + b)\n",
        "\\end{equation*}"
      ]
    },
    {
      "metadata": {
        "id": "y8BeIMYotNFz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fc_units1 = 1024\n",
        "\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, ...])  # we need to collapse the volume into a vector of pixels (but why -1 again?)\n",
        "\n",
        "w_fc1 = tf.Variable(tf.truncated_normal([ , ], stddev=0.1)) # expects a vector of pixels\n",
        "b_fc1 = tf.Variable(tf.constant(0.1, shape=[...]))\n",
        "\n",
        "h_fc1 = ...\n",
        "\n",
        "# sanity check for the output volume\n",
        "print(h_fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ihzsn-Itv52h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the Output Layer\n",
        "\n",
        "Remember the output layer is returning the class probabilities (10 classes)"
      ]
    },
    {
      "metadata": {
        "id": "AubqFTJYvCMf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "w_fc2 = tf.Variable(tf.truncated_normal([ , ], stddev=0.1))\n",
        "b_fc2 = tf.Variable(tf.constant(0.1, shape=[...]))\n",
        "\n",
        "logits = ...\n",
        "\n",
        "print(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_E5JZf6twb0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Softmax! Lost Function! Optimization!"
      ]
    },
    {
      "metadata": {
        "id": "wt3CFuhswYHr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1MQrGJKxJNA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some metrics to track while training"
      ]
    },
    {
      "metadata": {
        "id": "U5Ws7Ysmw71n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "correct_predictions = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7SthjZDxV2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's train our model"
      ]
    },
    {
      "metadata": {
        "id": "0aui1JzdxRE9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# initialize tensorflow variables\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7YaZ2YRxeot",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# run model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(num_epochs):\n",
        "        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "        x_batch = x_batch.reshape([batch_size, 28, 28, 1]) # we no longer want a flat vector of pixels\n",
        "        optimizer.run(feed_dict = {x: x_batch, y_: y_batch})\n",
        "        if i % 100 == 0:\n",
        "            acc = accuracy.eval(feed_dict = {x: x_batch, y_: y_batch})\n",
        "            loss = cross_entropy_loss.eval(feed_dict = {x: x_batch, y_: y_batch})\n",
        "            print(\"Epoch: {}, accuracy: {}, loss: {}\".format(i, acc, loss))\n",
        "\n",
        "    acc = accuracy.eval(feed_dict = {x: mnist.test.images.reshape([-1, 28, 28, 1]), y_:mnist.test.labels}) # here too\n",
        "    print(\"Test accuracy: {}\".format(acc))\n",
        "    saver.save(sess, \"./saved_model.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woZHHjOlz9IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Print out some pictures like we did for the previous workshops"
      ]
    },
    {
      "metadata": {
        "id": "Ksnh8bgQx2ap",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def gen_image(arr):\n",
        "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
        "    plt.imshow(two_d, interpolation='nearest', cmap='gray')\n",
        "    return plt\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"./saved_model.ckpt\")\n",
        "    X_new_scaled = mnist.test.images\n",
        "    z = logits.eval(feed_dict={x: X_new_scaled.reshape([-1, 28, 28, 1])})\n",
        "    y_pred = np.argmax(z, axis=1)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    print(accuracy.eval(feed_dict={x: mnist.test.images.reshape([-1, 28, 28, 1]), y_: mnist.test.labels}))\n",
        "    for i in range(100):\n",
        "        if i%3 == 0:\n",
        "            gen_image(mnist.test.images[i]).show()\n",
        "            print(\"Predition: \", y_pred[i])\n",
        "            print(\"Actual label: \", np.argmax(mnist.test.labels[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xv2R1ylCcjZV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Filter Visualization\n",
        "\n",
        "Let's take a look at how our model \"sees\" the inputs we give."
      ]
    },
    {
      "metadata": {
        "id": "uBIC0pJoz8TL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "imageToUse = np.reshape(mnist.test.images[4], [28,28])\n",
        "plt.imshow(imageToUse, interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39mRqaIJbOue",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def getActivations(layer,stimuli, sess):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1, 28,28,1])})\n",
        "    plotNNFilter(units)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmekU-lzblsA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4Rpmm5zcISw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, \"./saved_model.ckpt\")\n",
        "  getActivations(h_relu1,imageToUse, sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "boJ_nH0ecTx6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}